{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c660eb7-7677-47f8-845e-224f8b1bef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LunaTrainingApp:\n",
    "   def __init__(self, sys_argv=None):\n",
    "        if sys_argv is None:\n",
    "            sys_argv = sys.argv[1:]\n",
    "\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--num-workers',help='Number of worker processes for background data loading',\n",
    "                           default = 8,\n",
    "                           type = int,)\n",
    "\n",
    "     ....\n",
    "     self.cli_args = parser.parse_args(sys_argv)\n",
    "     self.time_str = datetime.datetime.now().strftime('%Y-%m-%d_%H,%M,%S')\n",
    "     ....\n",
    "\n",
    "#这里是一个日志的记录\n",
    "def main(self):\n",
    "    # log.info(\"Strating {}, {}\".format(type(self)._name_,self.cli_args))\n",
    "    log.info(f\"Initialized {type(self).__name__} with args: {self.cli_args}\")\n",
    "\n",
    "    ....\n",
    "if __name__ == '__main__':\n",
    "    LunaTrainingApp.main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8caac9e-9d11-4c9a-968a-11251b7369e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from util.util import importstr\n",
    "from util.logconf import logging\n",
    "log = logging.getLogger('nb')\n",
    "\n",
    "def run(app,*argv):\n",
    "    argv = list(argv)\n",
    "    argv.insert(0, '--num-workers=4')\n",
    "    # log.info(\"Running: {} ({!r}).main()\".format(app,argv))\n",
    "    log.info(f\"Running: {app} ({argv!r}).main()\")\n",
    "\n",
    "    app_cls = importstr(*app.rsplit('.',1))\n",
    "    app_cls(argv).main()\n",
    "\n",
    "    # log.info(\"Finished: {}({!r}).main()\".format(app,argv))\n",
    "    log.info(f\"Finished: {app}({argv!r}).main()\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5eda87-7347-445c-9cd6-19412d0af0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "run('LunaTrainingApp','--num-workers=4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac246ec0-f70a-4b12-9f87-365c356e61c5",
   "metadata": {},
   "source": [
    "1:gpu\n",
    "2:模型初始化\n",
    "3：优化器定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3839f691-b16f-4471-8c98-a09e9e5dc6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LunaTrainingApp:\n",
    "    def __init__(self,sys_argv=None):\n",
    "        # ....\n",
    "        # self.use_cuda = torch.cuda.is_available()\n",
    "        # self.device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "\n",
    "        ...\n",
    "        if torch.backends.mps.is_available():  # 检查 Metal API 是否可用\n",
    "            self.device = torch.device('mps')  # 使用 Metal API (仅限 Apple Silicon)\n",
    "            log.info(f\"Using Metal API on Apple Silicon devices.\")\n",
    "        elif torch.cuda.is_available():  # 检查 CUDA 是否可用（适用于支持 CUDA 的设备）\n",
    "            self.device = torch.device(\"cuda\")\n",
    "            log.info(f\"Using CUDA: {torch.cuda.device_count()} devices.\")\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")  # 如果没有 CUDA 或 Metal API，使用 CPU\n",
    "            log.info(f\"Using CPU.\")\n",
    "\n",
    "        self.model = self.initModel()\n",
    "        selff.optimizer = self.initOptimizer()\n",
    "\n",
    "     # def initModel(self):\n",
    "     #     model = LunaModel()\n",
    "     #     if self.use_cuda:\n",
    "     #         # log.info(\"Using CUDA: {} devices.\".format(torch.cuda.device_count()))\n",
    "     #           log.info(f\"Using CUDA: {torch.cuda.device_count()} devices.\")\n",
    "     #         if torch.cuda.device_count() > 1:\n",
    "     #             model = nn.DataParallel(model)\n",
    "     #         model = model.to(self.device)\n",
    "     #    return model\n",
    "\n",
    "       def initModel(self):\n",
    "        model = LunaModel()\n",
    "        if self.device.type == 'cuda' or self.device.type == 'mps':  # 检查设备类型\n",
    "            log.info(f\"Using device: {self.device}.\")\n",
    "            if torch.cuda.device_count() > 1 and self.device.type == 'cuda':  # 支持多GPU时使用 DataParallel\n",
    "                model = nn.DataParallel(model)\n",
    "            model = model.to(self.device)\n",
    "        return model\n",
    "\n",
    "     def initOptimizer(self):\n",
    "         return SGD(self.model.parameters(),lr = 0.001,momentum=0.99)\n",
    "         # return Adam(self.mode.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c1fc6e-873b-4e74-8a03-808cb1c22a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c82cd1-a781-4879-868f-e58fa886bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def initTrainDl(self):\n",
    "#     train_ds = LunaDataset(\n",
    "#     val_stride=10,\n",
    "#     isValSet_bool=False,\n",
    "#     )\n",
    "#     batch_size = self.cli_args.batch_size\n",
    "\n",
    "#     if self.use_cuda:\n",
    "#         batch_size *= torch.cuda.device_count()\n",
    "        \n",
    "#     train_dl = DataLoader(\n",
    "#         train_ds,\n",
    "#         batch_size=batch_size,\n",
    "#         num_workers=self.cli_args.num_workers,\n",
    "#         pin_memory = self.use_cuda,\n",
    "#     )    \n",
    "\n",
    "#     return train_dl\n",
    "\n",
    "# def initValDl(self):\n",
    "#     val_ds = LunaDataset(\n",
    "#         val_stride=10,\n",
    "#         isValSet_bool=True,\n",
    "#     )\n",
    "#     batch_size = self.cli_args.batch_size\n",
    "\n",
    "#     if self.use_cuda:\n",
    "#         batch_size *= torch.cuda.device_count()\n",
    "        \n",
    "#     val_dl = DataLoader(\n",
    "#         val_ds,\n",
    "#         batch_size=batch_size,\n",
    "#         num_workers=self.cli_args.num_workers,\n",
    "#         pin_memory = self.use_cuda,\n",
    "#     )    \n",
    "\n",
    "#     return val_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f367a38-9f73-43ef-b273-0e23ddf6eb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initTrainDl(self):\n",
    "    train_ds = LunaDataset(\n",
    "        val_stride=10,\n",
    "        isValSet_bool=False,\n",
    "    )\n",
    "    batch_size = self.cli_args.batch_size\n",
    "\n",
    "    # 直接设置 batch_size 和 pin_memory，不做设备判断\n",
    "    batch_size *= 1  # 对于苹果电脑，这里我们不需要调整 batch_size\n",
    "    pin_memory = False  # 禁用 pin_memory，因为没有 CUDA 或 Metal 加速\n",
    "\n",
    "    train_dl = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=self.cli_args.num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )    \n",
    "\n",
    "    return train_dl\n",
    "\n",
    "def initValDl(self):\n",
    "    val_ds = LunaDataset(\n",
    "        val_stride=10,\n",
    "        isValSet_bool=True,\n",
    "    )\n",
    "    batch_size = self.cli_args.batch_size\n",
    "\n",
    "    # 直接设置 batch_size 和 pin_memory，不做设备判断\n",
    "    batch_size *= 1  # 对于苹果电脑，这里我们不需要调整 batch_size\n",
    "    pin_memory = False  # 禁用 pin_memory，因为没有 CUDA 或 Metal 加速\n",
    "\n",
    "    val_dl = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=self.cli_args.num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )    \n",
    "\n",
    "    return val_dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a58b55e-7b84-4047-b0ff-4d96257114a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(self):\n",
    "    # log.info(\"Strating {}, {}\".format(type(self)._name_,self.cli_args))\n",
    "    log.info(f\"Initialized {type(self).__name__} with args: {self.cli_args}\")\n",
    "    train_dl = self.initTrainDl()\n",
    "    val_dl = self.initValDl()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a8a8a5-cb39-4e85-94ea-dc083952614f",
   "metadata": {},
   "source": [
    "模型核心部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fde189-5b74-4747-bd79-02273c82b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LunaBlock(nn.Module):\n",
    "    def __init__(self,in_channels,conv_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels,conv_channels,kernel_size=3,padding=1,bias=True)\n",
    "        self.relu1 = nn.ReLU(inplace = True)\n",
    "\n",
    "        # self.conv2 = nn.Conv3d(in_channels,conv_channels,kernel_size=3,padding=1,bias=True)\n",
    "         self.conv2 = nn.Conv3d(conv_channels, conv_channels, kernel_size=3, padding=1, bias=True)\n",
    "        self.relu2 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.maxpool = nn.MaxPool3d(2,2)\n",
    "\n",
    "     def forward(self,input_batch):\n",
    "         block_out = self.conv1(input_batch)\n",
    "         block_out = self.relu1(block_out)\n",
    "         block_out = self.conv2(block_out)\n",
    "         block_out = self.relu2(block_out)\n",
    "         block_out = self.maxpool(block_out)\n",
    "\n",
    "         return block_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841661b8-ebb8-490a-9523-73324531d95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class LunaModel(nn.Module):\n",
    "    def __init__(self,in_channels=1, conv_channels=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tail_batchnorm = nn.BatchNorm3d(1)\n",
    "        \n",
    "        self.block1 = LunaBlock(in_channels, conv_channels)\n",
    "        self.block2 = LunaBlock(conv_channels, conv_channels*2)\n",
    "        self.block3 = LunaBlock(in_channels * 2, conv_channels*4)\n",
    "        self.block4 = LunaBlock(in_channels * 4, conv_channels*8)\n",
    "\n",
    "        self.head_linear = nn.Linear(1152,2)\n",
    "        # self.head_linear = nn.Linear(conv_channels * 8 * 4 * 4 * 4, 2)\n",
    "\n",
    "        self.head_softmax = nn.Softmax(dim = 1)\n",
    "        \n",
    "        self.__init__weights()\n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        bn_output = self.tail_batchnorm(input_batch)\n",
    "        \n",
    "        block_out = self.block1(bn_output)\n",
    "        block_out = self.block2(block_out)\n",
    "        block_out = self.block3(block_out)\n",
    "        block_out = self.block4(block_out)\n",
    "        \n",
    "        conv_flat = block_out.view(block_out.size(0),-1)\n",
    "        linear_output = self.head_linear(conv_flat)\n",
    "        return linear_output,self.head_softmax(linear_output)\n",
    "\n",
    "     def __init__weights(self):\n",
    "         for m in self.modules():\n",
    "             if type(m) in (nn.Linear,nn.Conv3d,nn.Conv2d,nn.ConvTranspose2d,nn.ConvTranspose3d):\n",
    "                 nn.init.kaiming_normal_(\n",
    "                     m.weight.data, a=0, mode='fan_out',nonlinearity = 'relu',\n",
    "                 )\n",
    "\n",
    "                 if m.bias is not None:\n",
    "                     fan_in,fan_out = nn.init._calculate_fan_in_and_out(m.weight.data)\n",
    "                     bound = 1 / math.sqrt(fan_out)\n",
    "                     nn.init.normal_(m.bias,-bound,bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117e3899-14e3-4866-b593-c4d1a47cc3bf",
   "metadata": {},
   "source": [
    "定义损失计算 和 训练验证环节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34a7be1-4293-47d6-bb28-b34844e8428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main(self):\n",
    "#     # log.info(\"Strating {}, {}\".format(type(self)._name_,self.cli_args))\n",
    "#     log.info(f\"Initialized {type(self).__name__} with args: {self.cli_args}\")\n",
    "#     train_dl = self.initTrainDl()\n",
    "#     val_dl = self.initValDl()\n",
    "\n",
    "#     for epoch_ndx in range(1,self.cli_args.epochs + 1):\n",
    "#         log.info(\"Epoch {} of {}, {}/{} batches of size {} * {}\".format(\n",
    "#             epoch_ndx,\n",
    "#             self.cli_args,epochs,\n",
    "#             len(train_dl),\n",
    "#             len(val_dl),\n",
    "#             self.cli_args.batch_size,\n",
    "#             (torch.cuda.device_count() if self.use_cuda else 1),\n",
    "#         ))\n",
    "\n",
    "#         trnMetrics_t = self.doTraining(epoch_ndx, val_dl)\n",
    "#         self.logMetrics(epoch_ndx, 'trn',trnMetrics_t)\n",
    "\n",
    "#         valMetrics_t = self.doValidation(epoch_ndx, val_dl)\n",
    "#         self.logMetrics(epoch_ndx, 'val', valMetrics_t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81c0388-0d7d-4b1a-aafa-d81b80a7cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(self):\n",
    "    # log.info(\"Strating {}, {}\".format(type(self)._name_,self.cli_args))\n",
    "    log.info(f\"Initialized {type(self).__name__} with args: {self.cli_args}\")\n",
    "    train_dl = self.initTrainDl()\n",
    "    val_dl = self.initValDl()\n",
    "\n",
    "    for epoch_ndx in range(1, self.cli_args.epochs + 1):\n",
    "        log.info(\"Epoch {} of {}, {}/{} batches of size {} * {}\".format(\n",
    "            epoch_ndx,\n",
    "            self.cli_args.epochs,\n",
    "            len(train_dl),\n",
    "            len(val_dl),\n",
    "            self.cli_args.batch_size,\n",
    "            1,  # Only 1 device (CPU) on Apple machines\n",
    "        ))\n",
    "\n",
    "        trnMetrics_t = self.doTraining(epoch_ndx, val_dl)\n",
    "        self.logMetrics(epoch_ndx, 'trn', trnMetrics_t)\n",
    "\n",
    "        valMetrics_t = self.doValidation(epoch_ndx, val_dl)\n",
    "        self.logMetrics(epoch_ndx, 'val', valMetrics_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d4ee41-2659-4087-9871-693fa58099cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS_LABEL_NDX = 0\n",
    "METRICS_PRED_NDX = 1\n",
    "METRICS_LOSS_NDX = 2\n",
    "METRICS_SIZE = 3\n",
    "def doTraining(self,epoch_ndx,train_dl):\n",
    "    self.model.train()\n",
    "\n",
    "    trnMetrics_g = torch.zeros(\n",
    "        METRICS_SIZE,\n",
    "        len(train_dl.dataset),\n",
    "        device = self.device\n",
    "    )\n",
    "\n",
    "    batch_iter = enumerateWithEstimate(\n",
    "        train_dl,\n",
    "        \"E{} Training\".format(epoch_ndx),\n",
    "        start_ndx = train_dl.num_workers,\n",
    "    )\n",
    "\n",
    "    for batch_ndx, batch_tup in batch_iter:\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        loss_var = self.computeBatchLoss(\n",
    "            batch_ndx,\n",
    "            batch_tup,\n",
    "            train_dl.batch_size,\n",
    "            trnMetrics_g\n",
    "        )\n",
    "\n",
    "        loss_var.backward()\n",
    "        self.optimizer.step()\n",
    "    self.totalTrainingSamples_count += len(train_dl.dataset)\n",
    "    return trnMetrics_g.to('cpu')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79efcc97-f9e2-4973-954b-8037d45147ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doValidation(self,epoch_ndx,train_dl):\n",
    "    with torch.no_grad():\n",
    "        self.model.eval()\n",
    "        \n",
    "        valMetrics_g = torch.zeros(\n",
    "            METRICS_SIZE,\n",
    "            len(val_dl.dataset),\n",
    "            device = self.device\n",
    "        )\n",
    "\n",
    "        # batch_iter = enumerateWithEstimate(\n",
    "        #     val_dl,\n",
    "        #     f\"E{epoch_ndx} Validation\",\n",
    "        #     start_ndx=val_dl.num_workers,\n",
    "        # )\n",
    "\n",
    "         for batch_ndx, batch_tup in batch_iter:\n",
    "             self.computeBatchLoss(\n",
    "                  batch_ndx,\n",
    "                  batch_tup,\n",
    "                  val_dl.batch_size,\n",
    "                  valMetrics_g\n",
    "             )\n",
    "\n",
    "     return valMetrics_g.to('cpu')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e714f86-1de9-4464-8368-d8b8da4d6695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeBatchLoss(self,batch_ndx,batch_tup,batch_size,metrics_g):\n",
    "    input_t, label_t, _series_list, _center_list = batch_tup\n",
    "\n",
    "    input_g = input_t.to(self.device,non_block=True)\n",
    "    label_g = label_t.to(self.device,non_block=True)\n",
    "\n",
    "    logits_g,probability_g = self.model(input_g)\n",
    "\n",
    "    loss_func = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    loss_g = loss_func(logits_g, label_g[:,1])\n",
    "\n",
    "    start_ndx = batch_ndx * batch_size\n",
    "    end_ndx = start_ndx + label_t.size(0)\n",
    "\n",
    "    metrics_g[METRICS_LABEL_NDX,start_ndx:end_ndx] = label_g[:,1].detach()\n",
    "    metrics_g[METRICS_PRED_NDX,start_ndx:end_ndx] = probability_g[:,1].detach()\n",
    "    metrics_g[METRICS_LOSS_NDX,start_ndx:end_ndx] = loss_g.detach()\n",
    "\n",
    "    return loss_g.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96229ea4-ed7e-41de-89fb-93a65b775bf2",
   "metadata": {},
   "source": [
    "在日志中保存重要信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b701cc8-ed5a-435e-afd2-508eab652477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logMetrics(self,epoch_ndx,mode_str,metrics_t,classificationThreshold = 0.5):\n",
    "    self.initTensorboardWriters()\n",
    "    log.info(\"E{} {}\".format(epoch_ndx, type(self).__name__))\n",
    "\n",
    "    negLabel_mask = metrics_t[METRICS_LABEL_NDX] <= classificationThreshold\n",
    "    negPred_mask = metrics_t[METRICS_PRED_NDX] <= classificationThreshold\n",
    "\n",
    "    posLabel_mask = ~negLabel_mask\n",
    "    posPred_mask = ~negPred_mask\n",
    "\n",
    "    neg_count = int((negLabel_mask & negPred_mask).sum())\n",
    "    pos_count = int((posLabel_mask & posPred_mask).sum())\n",
    "\n",
    "    metrics_dict = {}\n",
    "    metrics_dict['loss/all'] = metrics_t[METRICS_LOSS_NDX].mean()\n",
    "    metrics_dict['loss/neg'] = metrics_t[METRICS_LOSS_NDX,negLabel_mask].mean()\n",
    "    metrics_dict['loss/pos'] = metrics_t[METRICS_LOSS_NDX,posLabel_mask].mean()\n",
    "\n",
    "    metrics_dict['correct/all'] = (pos_correct + neg_correct) / np.float32(metrics_t.shape[1]) * 100\n",
    "    metrics_dict['correct/neg'] = neg_correct / np.float32(neg_count) * 100\n",
    "    metrics_dict['correct/pos'] = pos_correct / np.float32(pos_count) * 100\n",
    "\n",
    "    log.info((\"E{} {:8} {loss/all:,4f} loss,\" + \"{correct/all:-5.1f}% correct,\").format(epoch_ndx, mode_str, **metrics_dict))\n",
    "    log.info((\"E{} {:8} {loss/neg:,4f} loss,\" + \"{correct/neg:-5.1f}% correct ({neg_correct:} of {neg_count:})\").format(epoch_ndx, mode_str+'_neg',neg_correct=neg_correct,neg_count=neg_count, **metrics_dict))\n",
    "    log.info((\"E{} {:8} {loss/pos:,4f} loss,\" + \"{correct/pos:-5.1f}% correct ({neg_correct:} of {neg_count:})\").format(epoch_ndx, mode_str+'_pos',pos_correct=pos_correct,pos_count=pos_count, **metrics_dict))\n",
    "\n",
    "    writer = getattr(self,mode_str + '_writer')\n",
    "    for key,value in metrics_dict.items():\n",
    "        writer.add_scalar(key, value,self.totalTrainingSamples_count)\n",
    "    writer.add_pr_curve('pr',metrics_t[METRICS_LABEL_NDX], metrics_t[METRICS_PRED_NDX],self.totalTrainingSamples_count)\n",
    "\n",
    "        bin = [x/50.0 for x in range(51)]\n",
    "\n",
    "        negHist_mask = negLabel_mask & (metrics_t[METRICS_PRED_NDX] > 0.01)\n",
    "        posHist_mask = posLabel_mask & (metrics_t[METRICS_PRED_NDX] < 0.99)\n",
    "\n",
    "        if  negHist_mask.any():\n",
    "            writer.add_histogram('is_neg', metrics_t[METRICS_PRED_NDX,negHist_mask],self.totalTrainingSamples_count,bins=bins)\n",
    "\n",
    "        if  posHist_mask.any():\n",
    "            writer.add_histogram('is_pos', metrics_t[METRICS_PRED_NDX,posHist_mask],self.totalTrainingSamples_count,bins=bins)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54726519-6007-4c77-9f81-99f22151188d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bd388c-71d3-40e8-882a-4294194bc7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cbb587-5ed0-4956-a345-33072ea0009d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
